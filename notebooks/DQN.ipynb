{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db9cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from distutils.util import strtobool\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from stable_baselines3.common.atari_wrappers import (\n",
    "    ClipRewardEnv,\n",
    "    EpisodicLifeEnv,\n",
    "    FireResetEnv,\n",
    "    MaxAndSkipEnv,\n",
    "    NoopResetEnv,\n",
    ")\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    args = {\n",
    "        \"exp-name\": \"AtariDQN\",\n",
    "        \"seed\": 1,\n",
    "        \"torch-deterministic\": True,\n",
    "        \"cuda\": True,\n",
    "        \"track\": False,\n",
    "        \"wandb-project-name\": \"cleanRL\",\n",
    "        \"wandb-entity\": None,\n",
    "        \"capture-video\": False,\n",
    "        \"save-model\": False,\n",
    "        \"upload-model\": False,\n",
    "        \"hf-entity\": \"\",\n",
    "        \"env-id\": \"BreakoutNoFrameskip-v4\",\n",
    "        \"total-timesteps\": 10000000,\n",
    "        \"learning-rate\": 1e-4,\n",
    "        \"num-envs\": 1,\n",
    "        \"buffer-size\": 1000000,\n",
    "        \"gamma\": 0.99,\n",
    "        \"tau\": 1.,\n",
    "        \"target-network-frequency\": 1000,\n",
    "        \"batch-size\": 32,\n",
    "        \"start-e\": 1,\n",
    "        \"end-e\": 0.01,\n",
    "        \"exploration-fraction\": 0.20,\n",
    "        \"learning-starts\": 80000,\n",
    "        \"train-frequency\": 4\n",
    "    }\n",
    "\n",
    "    assert args[\"num-envs\"] == 1, \"vectorized envs are not supported at the moment\"\n",
    "\n",
    "    # Convert the dictionary to a defaultdict with default value as None\n",
    "    args_dict = defaultdict(lambda: None, args)\n",
    "    \n",
    "    \n",
    "    args_dict = dict(args_dict)\n",
    "\n",
    "    class Args:\n",
    "        def __init__(self, **kwargs):\n",
    "            self.__dict__.update(kwargs)\n",
    "            for k in list(self.__dict__.keys()):\n",
    "                self.__dict__[k.replace(\"-\",\"_\")]=self.__dict__[k]\n",
    "    args = Args(**args_dict)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def make_env(env_id, seed, idx, capture_video, run_name):\n",
    "    def thunk():\n",
    "        if capture_video and idx == 0:\n",
    "            env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "            env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\")\n",
    "        else:\n",
    "            env = gym.make(env_id)\n",
    "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "        env = NoopResetEnv(env, noop_max=30)\n",
    "        env = MaxAndSkipEnv(env, skip=4)\n",
    "        env = EpisodicLifeEnv(env)\n",
    "        if \"FIRE\" in env.unwrapped.get_action_meanings():\n",
    "            env = FireResetEnv(env)\n",
    "        env = ClipRewardEnv(env)\n",
    "        env = gym.wrappers.ResizeObservation(env, (84, 84))\n",
    "        env = gym.wrappers.GrayScaleObservation(env)\n",
    "        env = gym.wrappers.FrameStack(env, 4)\n",
    "        env.action_space.seed(seed)\n",
    "\n",
    "        return env\n",
    "\n",
    "    return thunk\n",
    "\n",
    "\n",
    "# ALGO LOGIC: initialize agent here:\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, 8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, env.single_action_space.n),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x / 255.0)\n",
    "\n",
    "\n",
    "def linear_schedule(start_e: float, end_e: float, duration: int, t: int):\n",
    "    slope = (end_e - start_e) / duration\n",
    "    return max(slope * t + start_e, end_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ab5c19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BreakoutNoFrameskip-v4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parse_args()\n",
    "args.env_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3430ad9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "/Users/sni/Documents/Projects/Telluride/BrainDishSiMulator/venv/lib/python3.9/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 28.24GB > 21.12GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step=139, episodic_return=[1.]\n",
      "global_step=324, episodic_return=[2.]\n",
      "global_step=435, episodic_return=[0.]\n",
      "global_step=673, episodic_return=[3.]\n",
      "global_step=935, episodic_return=[3.]\n",
      "global_step=1141, episodic_return=[2.]\n",
      "global_step=1352, episodic_return=[2.]\n",
      "global_step=1495, episodic_return=[1.]\n",
      "global_step=1608, episodic_return=[0.]\n",
      "global_step=1767, episodic_return=[1.]\n",
      "global_step=1882, episodic_return=[0.]\n",
      "global_step=1995, episodic_return=[0.]\n",
      "global_step=2201, episodic_return=[2.]\n",
      "global_step=2312, episodic_return=[0.]\n",
      "global_step=2471, episodic_return=[1.]\n",
      "global_step=2678, episodic_return=[2.]\n",
      "global_step=2819, episodic_return=[1.]\n",
      "global_step=2978, episodic_return=[1.]\n",
      "global_step=3091, episodic_return=[0.]\n",
      "global_step=3279, episodic_return=[2.]\n",
      "global_step=3468, episodic_return=[2.]\n",
      "global_step=3677, episodic_return=[2.]\n",
      "global_step=3861, episodic_return=[2.]\n",
      "global_step=3974, episodic_return=[0.]\n",
      "global_step=4133, episodic_return=[1.]\n",
      "global_step=4294, episodic_return=[1.]\n",
      "global_step=4407, episodic_return=[0.]\n",
      "global_step=4522, episodic_return=[0.]\n",
      "global_step=4681, episodic_return=[1.]\n",
      "global_step=4916, episodic_return=[3.]\n",
      "global_step=5075, episodic_return=[1.]\n",
      "global_step=5216, episodic_return=[1.]\n",
      "global_step=5403, episodic_return=[2.]\n",
      "global_step=5562, episodic_return=[1.]\n",
      "global_step=5677, episodic_return=[0.]\n",
      "global_step=5847, episodic_return=[2.]\n",
      "global_step=5958, episodic_return=[0.]\n",
      "global_step=6073, episodic_return=[0.]\n",
      "global_step=6188, episodic_return=[0.]\n",
      "global_step=6303, episodic_return=[0.]\n",
      "global_step=6489, episodic_return=[2.]\n",
      "global_step=6600, episodic_return=[0.]\n",
      "global_step=6715, episodic_return=[0.]\n",
      "global_step=6887, episodic_return=[2.]\n",
      "global_step=7171, episodic_return=[4.]\n",
      "global_step=7427, episodic_return=[3.]\n",
      "global_step=7615, episodic_return=[2.]\n",
      "global_step=7801, episodic_return=[2.]\n",
      "global_step=7963, episodic_return=[1.]\n",
      "global_step=8173, episodic_return=[2.]\n",
      "global_step=8528, episodic_return=[6.]\n",
      "global_step=8643, episodic_return=[0.]\n",
      "global_step=8928, episodic_return=[4.]\n",
      "global_step=9211, episodic_return=[4.]\n",
      "global_step=9324, episodic_return=[0.]\n",
      "global_step=9437, episodic_return=[0.]\n",
      "global_step=9613, episodic_return=[2.]\n",
      "global_step=9802, episodic_return=[2.]\n",
      "global_step=9915, episodic_return=[0.]\n",
      "global_step=10075, episodic_return=[1.]\n",
      "global_step=10286, episodic_return=[2.]\n",
      "global_step=10473, episodic_return=[2.]\n",
      "global_step=10634, episodic_return=[1.]\n",
      "global_step=10972, episodic_return=[5.]\n",
      "global_step=11087, episodic_return=[0.]\n",
      "global_step=11202, episodic_return=[0.]\n",
      "global_step=11343, episodic_return=[1.]\n",
      "global_step=11484, episodic_return=[1.]\n",
      "global_step=11597, episodic_return=[0.]\n",
      "global_step=11784, episodic_return=[2.]\n",
      "global_step=11899, episodic_return=[0.]\n",
      "global_step=12042, episodic_return=[1.]\n",
      "global_step=12199, episodic_return=[1.]\n",
      "global_step=12385, episodic_return=[2.]\n",
      "global_step=12593, episodic_return=[2.]\n",
      "global_step=12708, episodic_return=[0.]\n",
      "global_step=12823, episodic_return=[0.]\n",
      "global_step=12938, episodic_return=[0.]\n",
      "global_step=13097, episodic_return=[1.]\n",
      "global_step=13289, episodic_return=[2.]\n",
      "global_step=13476, episodic_return=[2.]\n",
      "global_step=13591, episodic_return=[0.]\n",
      "global_step=13798, episodic_return=[2.]\n",
      "global_step=13911, episodic_return=[0.]\n",
      "global_step=14196, episodic_return=[4.]\n",
      "global_step=14432, episodic_return=[3.]\n",
      "global_step=14593, episodic_return=[1.]\n",
      "global_step=14757, episodic_return=[1.]\n",
      "global_step=15011, episodic_return=[3.]\n",
      "global_step=15247, episodic_return=[3.]\n",
      "global_step=15358, episodic_return=[0.]\n",
      "global_step=15471, episodic_return=[0.]\n",
      "global_step=15616, episodic_return=[1.]\n",
      "global_step=15759, episodic_return=[1.]\n",
      "global_step=15920, episodic_return=[1.]\n",
      "global_step=16031, episodic_return=[0.]\n",
      "global_step=16191, episodic_return=[1.]\n",
      "global_step=16381, episodic_return=[2.]\n",
      "global_step=16522, episodic_return=[1.]\n",
      "global_step=16683, episodic_return=[1.]\n",
      "global_step=16798, episodic_return=[0.]\n",
      "global_step=16911, episodic_return=[0.]\n",
      "global_step=17024, episodic_return=[0.]\n",
      "global_step=17137, episodic_return=[0.]\n",
      "global_step=17250, episodic_return=[0.]\n",
      "global_step=17409, episodic_return=[1.]\n",
      "global_step=17520, episodic_return=[0.]\n",
      "global_step=17633, episodic_return=[0.]\n",
      "global_step=17795, episodic_return=[1.]\n",
      "global_step=17983, episodic_return=[2.]\n",
      "global_step=18098, episodic_return=[0.]\n",
      "global_step=18241, episodic_return=[1.]\n",
      "global_step=18354, episodic_return=[0.]\n",
      "global_step=18465, episodic_return=[0.]\n",
      "global_step=18580, episodic_return=[0.]\n",
      "global_step=18739, episodic_return=[1.]\n",
      "global_step=18852, episodic_return=[0.]\n",
      "global_step=18967, episodic_return=[0.]\n",
      "global_step=19082, episodic_return=[0.]\n",
      "global_step=19225, episodic_return=[1.]\n",
      "global_step=19340, episodic_return=[0.]\n",
      "global_step=19576, episodic_return=[3.]\n",
      "global_step=19733, episodic_return=[1.]\n",
      "global_step=19921, episodic_return=[2.]\n",
      "global_step=20178, episodic_return=[3.]\n",
      "global_step=20293, episodic_return=[0.]\n",
      "global_step=20436, episodic_return=[1.]\n",
      "global_step=20579, episodic_return=[1.]\n",
      "global_step=20690, episodic_return=[0.]\n",
      "global_step=20803, episodic_return=[0.]\n",
      "global_step=20918, episodic_return=[0.]\n",
      "global_step=21152, episodic_return=[3.]\n",
      "global_step=21344, episodic_return=[2.]\n",
      "global_step=21485, episodic_return=[1.]\n",
      "global_step=21774, episodic_return=[4.]\n",
      "global_step=21962, episodic_return=[2.]\n",
      "global_step=22077, episodic_return=[0.]\n",
      "global_step=22315, episodic_return=[3.]\n",
      "global_step=22572, episodic_return=[3.]\n",
      "global_step=22790, episodic_return=[3.]\n",
      "global_step=23026, episodic_return=[3.]\n",
      "global_step=23315, episodic_return=[5.]\n",
      "global_step=23474, episodic_return=[1.]\n",
      "global_step=23810, episodic_return=[5.]\n",
      "global_step=23921, episodic_return=[0.]\n",
      "global_step=24109, episodic_return=[2.]\n",
      "global_step=24250, episodic_return=[1.]\n",
      "global_step=24365, episodic_return=[0.]\n",
      "global_step=24553, episodic_return=[2.]\n",
      "global_step=24668, episodic_return=[0.]\n",
      "global_step=24783, episodic_return=[0.]\n",
      "global_step=25044, episodic_return=[4.]\n",
      "global_step=25250, episodic_return=[2.]\n",
      "global_step=25420, episodic_return=[2.]\n",
      "global_step=25605, episodic_return=[2.]\n",
      "global_step=25890, episodic_return=[4.]\n",
      "global_step=26003, episodic_return=[0.]\n",
      "global_step=26116, episodic_return=[0.]\n",
      "global_step=26229, episodic_return=[0.]\n",
      "global_step=26389, episodic_return=[1.]\n",
      "global_step=26502, episodic_return=[0.]\n",
      "global_step=26643, episodic_return=[1.]\n",
      "global_step=26878, episodic_return=[3.]\n",
      "global_step=27048, episodic_return=[2.]\n",
      "global_step=27219, episodic_return=[2.]\n",
      "global_step=27334, episodic_return=[0.]\n",
      "global_step=27447, episodic_return=[0.]\n",
      "global_step=27635, episodic_return=[2.]\n",
      "global_step=27748, episodic_return=[0.]\n",
      "global_step=27909, episodic_return=[1.]\n",
      "global_step=28204, episodic_return=[5.]\n",
      "global_step=28317, episodic_return=[0.]\n",
      "global_step=28481, episodic_return=[1.]\n",
      "global_step=28765, episodic_return=[4.]\n",
      "global_step=28880, episodic_return=[0.]\n",
      "global_step=29019, episodic_return=[1.]\n",
      "global_step=29132, episodic_return=[0.]\n",
      "global_step=29322, episodic_return=[2.]\n",
      "global_step=29461, episodic_return=[1.]\n",
      "global_step=29604, episodic_return=[1.]\n",
      "global_step=29743, episodic_return=[1.]\n",
      "global_step=29931, episodic_return=[2.]\n",
      "global_step=30042, episodic_return=[0.]\n",
      "global_step=30181, episodic_return=[1.]\n",
      "global_step=30371, episodic_return=[2.]\n",
      "global_step=30682, episodic_return=[4.]\n",
      "global_step=31015, episodic_return=[5.]\n",
      "global_step=31283, episodic_return=[4.]\n",
      "global_step=31396, episodic_return=[0.]\n",
      "global_step=31555, episodic_return=[1.]\n",
      "global_step=31763, episodic_return=[2.]\n",
      "global_step=31878, episodic_return=[0.]\n",
      "global_step=32134, episodic_return=[3.]\n",
      "global_step=32247, episodic_return=[0.]\n",
      "global_step=32388, episodic_return=[1.]\n",
      "global_step=32693, episodic_return=[4.]\n",
      "global_step=32856, episodic_return=[1.]\n",
      "global_step=32965, episodic_return=[0.]\n",
      "global_step=33248, episodic_return=[4.]\n",
      "global_step=33616, episodic_return=[9.]\n",
      "global_step=33729, episodic_return=[0.]\n",
      "global_step=33842, episodic_return=[0.]\n",
      "global_step=33955, episodic_return=[0.]\n",
      "global_step=34213, episodic_return=[3.]\n",
      "global_step=34400, episodic_return=[2.]\n",
      "global_step=34515, episodic_return=[0.]\n",
      "global_step=34674, episodic_return=[1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step=34813, episodic_return=[1.]\n",
      "global_step=34928, episodic_return=[0.]\n",
      "global_step=35043, episodic_return=[0.]\n",
      "global_step=35229, episodic_return=[2.]\n",
      "global_step=35368, episodic_return=[1.]\n",
      "global_step=35479, episodic_return=[0.]\n",
      "global_step=35622, episodic_return=[1.]\n",
      "global_step=35733, episodic_return=[0.]\n",
      "global_step=35876, episodic_return=[1.]\n",
      "global_step=35991, episodic_return=[0.]\n",
      "global_step=36150, episodic_return=[1.]\n",
      "global_step=36265, episodic_return=[0.]\n",
      "global_step=36378, episodic_return=[0.]\n",
      "global_step=36519, episodic_return=[1.]\n",
      "global_step=36632, episodic_return=[0.]\n",
      "global_step=36747, episodic_return=[0.]\n",
      "global_step=36890, episodic_return=[1.]\n",
      "global_step=37003, episodic_return=[0.]\n",
      "global_step=37142, episodic_return=[1.]\n",
      "global_step=37253, episodic_return=[0.]\n",
      "global_step=37583, episodic_return=[5.]\n",
      "global_step=37891, episodic_return=[4.]\n",
      "global_step=38032, episodic_return=[1.]\n",
      "global_step=38145, episodic_return=[0.]\n",
      "global_step=38391, episodic_return=[4.]\n",
      "global_step=38506, episodic_return=[0.]\n",
      "global_step=38619, episodic_return=[0.]\n",
      "global_step=38732, episodic_return=[0.]\n",
      "global_step=38891, episodic_return=[1.]\n",
      "global_step=39004, episodic_return=[0.]\n",
      "global_step=39115, episodic_return=[0.]\n",
      "global_step=39277, episodic_return=[1.]\n",
      "global_step=39441, episodic_return=[1.]\n",
      "global_step=39554, episodic_return=[0.]\n",
      "global_step=39669, episodic_return=[0.]\n",
      "global_step=39826, episodic_return=[1.]\n",
      "global_step=40036, episodic_return=[2.]\n",
      "global_step=40323, episodic_return=[4.]\n",
      "global_step=40436, episodic_return=[0.]\n",
      "global_step=40549, episodic_return=[0.]\n",
      "global_step=40756, episodic_return=[2.]\n",
      "global_step=40869, episodic_return=[0.]\n",
      "global_step=40984, episodic_return=[0.]\n",
      "global_step=41194, episodic_return=[2.]\n",
      "global_step=41307, episodic_return=[0.]\n",
      "global_step=41448, episodic_return=[1.]\n",
      "global_step=41753, episodic_return=[4.]\n",
      "global_step=41896, episodic_return=[1.]\n",
      "global_step=42011, episodic_return=[0.]\n",
      "global_step=42122, episodic_return=[0.]\n",
      "global_step=42235, episodic_return=[0.]\n",
      "global_step=42394, episodic_return=[1.]\n",
      "global_step=42509, episodic_return=[0.]\n",
      "global_step=42717, episodic_return=[2.]\n",
      "global_step=42855, episodic_return=[1.]\n",
      "global_step=42970, episodic_return=[0.]\n",
      "global_step=43083, episodic_return=[0.]\n",
      "global_step=43198, episodic_return=[0.]\n",
      "global_step=43357, episodic_return=[1.]\n",
      "global_step=43470, episodic_return=[0.]\n",
      "global_step=43662, episodic_return=[2.]\n",
      "global_step=43801, episodic_return=[1.]\n",
      "global_step=43991, episodic_return=[2.]\n",
      "global_step=44153, episodic_return=[1.]\n",
      "global_step=44268, episodic_return=[0.]\n",
      "global_step=44383, episodic_return=[0.]\n",
      "global_step=44772, episodic_return=[6.]\n",
      "global_step=44931, episodic_return=[1.]\n",
      "global_step=45119, episodic_return=[2.]\n",
      "global_step=45258, episodic_return=[1.]\n",
      "global_step=45373, episodic_return=[0.]\n",
      "global_step=45486, episodic_return=[0.]\n",
      "global_step=45601, episodic_return=[0.]\n",
      "global_step=45742, episodic_return=[1.]\n",
      "global_step=45881, episodic_return=[1.]\n",
      "global_step=45996, episodic_return=[0.]\n",
      "global_step=46230, episodic_return=[3.]\n",
      "global_step=46438, episodic_return=[2.]\n",
      "global_step=46644, episodic_return=[2.]\n",
      "global_step=46976, episodic_return=[5.]\n",
      "global_step=47140, episodic_return=[1.]\n",
      "global_step=47251, episodic_return=[0.]\n",
      "global_step=47364, episodic_return=[0.]\n",
      "global_step=47526, episodic_return=[1.]\n",
      "global_step=47641, episodic_return=[0.]\n",
      "global_step=47752, episodic_return=[0.]\n",
      "global_step=47913, episodic_return=[1.]\n",
      "global_step=48196, episodic_return=[4.]\n",
      "global_step=48432, episodic_return=[3.]\n",
      "global_step=48545, episodic_return=[0.]\n",
      "global_step=48733, episodic_return=[2.]\n",
      "global_step=48848, episodic_return=[0.]\n",
      "global_step=48963, episodic_return=[0.]\n",
      "global_step=49153, episodic_return=[2.]\n",
      "global_step=49438, episodic_return=[4.]\n",
      "global_step=49597, episodic_return=[1.]\n",
      "global_step=49710, episodic_return=[0.]\n",
      "global_step=49823, episodic_return=[0.]\n",
      "global_step=49936, episodic_return=[0.]\n",
      "global_step=50168, episodic_return=[3.]\n",
      "global_step=50327, episodic_return=[1.]\n",
      "global_step=50608, episodic_return=[4.]\n",
      "global_step=50792, episodic_return=[2.]\n",
      "global_step=50905, episodic_return=[0.]\n",
      "global_step=51018, episodic_return=[0.]\n",
      "global_step=51133, episodic_return=[0.]\n",
      "global_step=51321, episodic_return=[2.]\n",
      "global_step=51436, episodic_return=[0.]\n",
      "global_step=51549, episodic_return=[0.]\n",
      "global_step=51782, episodic_return=[3.]\n",
      "global_step=51941, episodic_return=[1.]\n",
      "global_step=52132, episodic_return=[2.]\n",
      "global_step=52372, episodic_return=[3.]\n",
      "global_step=52487, episodic_return=[0.]\n",
      "global_step=52673, episodic_return=[2.]\n",
      "global_step=52788, episodic_return=[0.]\n",
      "global_step=53026, episodic_return=[3.]\n",
      "global_step=53141, episodic_return=[0.]\n",
      "global_step=53329, episodic_return=[2.]\n",
      "global_step=53490, episodic_return=[1.]\n",
      "global_step=53603, episodic_return=[0.]\n",
      "global_step=53886, episodic_return=[4.]\n",
      "global_step=54168, episodic_return=[4.]\n",
      "global_step=54311, episodic_return=[1.]\n",
      "global_step=54593, episodic_return=[4.]\n",
      "global_step=54850, episodic_return=[3.]\n",
      "global_step=55011, episodic_return=[1.]\n",
      "global_step=55124, episodic_return=[0.]\n",
      "global_step=55237, episodic_return=[0.]\n",
      "global_step=55352, episodic_return=[0.]\n",
      "global_step=55540, episodic_return=[2.]\n",
      "global_step=55655, episodic_return=[0.]\n",
      "global_step=55768, episodic_return=[0.]\n",
      "global_step=55881, episodic_return=[0.]\n",
      "global_step=55994, episodic_return=[0.]\n",
      "global_step=56232, episodic_return=[3.]\n",
      "global_step=56391, episodic_return=[1.]\n",
      "global_step=56504, episodic_return=[0.]\n",
      "global_step=56619, episodic_return=[0.]\n",
      "global_step=56732, episodic_return=[0.]\n",
      "global_step=56847, episodic_return=[0.]\n",
      "global_step=56990, episodic_return=[1.]\n",
      "global_step=57194, episodic_return=[2.]\n",
      "global_step=57305, episodic_return=[0.]\n",
      "global_step=57622, episodic_return=[5.]\n",
      "global_step=57836, episodic_return=[3.]\n",
      "global_step=58141, episodic_return=[4.]\n",
      "global_step=58428, episodic_return=[4.]\n",
      "global_step=58543, episodic_return=[0.]\n",
      "global_step=58807, episodic_return=[4.]\n",
      "global_step=58971, episodic_return=[1.]\n",
      "global_step=59203, episodic_return=[3.]\n",
      "global_step=59391, episodic_return=[2.]\n",
      "global_step=59706, episodic_return=[5.]\n",
      "global_step=59819, episodic_return=[0.]\n",
      "global_step=59981, episodic_return=[1.]\n",
      "global_step=60152, episodic_return=[2.]\n",
      "global_step=60265, episodic_return=[0.]\n",
      "global_step=60655, episodic_return=[9.]\n",
      "global_step=60770, episodic_return=[0.]\n",
      "global_step=61081, episodic_return=[4.]\n",
      "global_step=61242, episodic_return=[1.]\n",
      "global_step=61480, episodic_return=[3.]\n",
      "global_step=61765, episodic_return=[8.]\n",
      "global_step=61880, episodic_return=[0.]\n",
      "global_step=61993, episodic_return=[0.]\n",
      "global_step=62106, episodic_return=[0.]\n",
      "global_step=62340, episodic_return=[3.]\n",
      "global_step=62453, episodic_return=[0.]\n",
      "global_step=62764, episodic_return=[7.]\n",
      "global_step=62879, episodic_return=[0.]\n",
      "global_step=63020, episodic_return=[1.]\n",
      "global_step=63135, episodic_return=[0.]\n",
      "global_step=63500, episodic_return=[6.]\n",
      "global_step=63609, episodic_return=[0.]\n",
      "global_step=63896, episodic_return=[4.]\n",
      "global_step=64011, episodic_return=[0.]\n",
      "global_step=64126, episodic_return=[0.]\n",
      "global_step=64411, episodic_return=[4.]\n",
      "global_step=64575, episodic_return=[1.]\n",
      "global_step=64783, episodic_return=[2.]\n",
      "global_step=64928, episodic_return=[1.]\n",
      "global_step=65039, episodic_return=[0.]\n",
      "global_step=65150, episodic_return=[0.]\n",
      "global_step=65265, episodic_return=[0.]\n",
      "global_step=65380, episodic_return=[0.]\n",
      "global_step=65664, episodic_return=[4.]\n",
      "global_step=65867, episodic_return=[2.]\n",
      "global_step=66028, episodic_return=[1.]\n",
      "global_step=66141, episodic_return=[0.]\n",
      "global_step=66256, episodic_return=[0.]\n",
      "global_step=66371, episodic_return=[0.]\n",
      "global_step=66678, episodic_return=[4.]\n",
      "global_step=66944, episodic_return=[4.]\n",
      "global_step=67059, episodic_return=[0.]\n",
      "global_step=67245, episodic_return=[2.]\n",
      "global_step=67358, episodic_return=[0.]\n",
      "global_step=67473, episodic_return=[0.]\n",
      "global_step=67633, episodic_return=[1.]\n",
      "global_step=67746, episodic_return=[0.]\n",
      "global_step=67907, episodic_return=[1.]\n",
      "global_step=68020, episodic_return=[0.]\n",
      "global_step=68179, episodic_return=[1.]\n",
      "global_step=68322, episodic_return=[1.]\n",
      "global_step=68481, episodic_return=[1.]\n",
      "global_step=68594, episodic_return=[0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step=68707, episodic_return=[0.]\n",
      "global_step=68913, episodic_return=[2.]\n",
      "global_step=69101, episodic_return=[2.]\n",
      "global_step=69214, episodic_return=[0.]\n",
      "global_step=69471, episodic_return=[3.]\n",
      "global_step=69681, episodic_return=[2.]\n",
      "global_step=69792, episodic_return=[0.]\n",
      "global_step=69952, episodic_return=[1.]\n",
      "global_step=70065, episodic_return=[0.]\n",
      "global_step=70180, episodic_return=[0.]\n",
      "global_step=70499, episodic_return=[5.]\n",
      "global_step=70661, episodic_return=[1.]\n",
      "global_step=70849, episodic_return=[2.]\n",
      "global_step=70960, episodic_return=[0.]\n",
      "global_step=71073, episodic_return=[0.]\n",
      "global_step=71230, episodic_return=[1.]\n",
      "global_step=71343, episodic_return=[0.]\n",
      "global_step=71676, episodic_return=[5.]\n",
      "global_step=71883, episodic_return=[2.]\n",
      "global_step=71996, episodic_return=[0.]\n",
      "global_step=72155, episodic_return=[1.]\n",
      "global_step=72268, episodic_return=[0.]\n",
      "global_step=72381, episodic_return=[0.]\n",
      "global_step=72767, episodic_return=[9.]\n",
      "global_step=72878, episodic_return=[0.]\n",
      "global_step=73065, episodic_return=[2.]\n",
      "global_step=73253, episodic_return=[2.]\n",
      "global_step=73437, episodic_return=[2.]\n",
      "global_step=73598, episodic_return=[1.]\n",
      "global_step=73738, episodic_return=[1.]\n",
      "global_step=73957, episodic_return=[3.]\n",
      "global_step=74267, episodic_return=[7.]\n",
      "global_step=74424, episodic_return=[1.]\n",
      "global_step=74535, episodic_return=[0.]\n",
      "global_step=74926, episodic_return=[9.]\n",
      "global_step=75041, episodic_return=[0.]\n",
      "global_step=75182, episodic_return=[1.]\n",
      "global_step=75398, episodic_return=[3.]\n",
      "global_step=75709, episodic_return=[4.]\n",
      "global_step=75824, episodic_return=[0.]\n",
      "global_step=75939, episodic_return=[0.]\n",
      "global_step=76050, episodic_return=[0.]\n",
      "global_step=76238, episodic_return=[2.]\n",
      "global_step=76349, episodic_return=[0.]\n",
      "global_step=76462, episodic_return=[0.]\n",
      "global_step=76621, episodic_return=[1.]\n",
      "global_step=76808, episodic_return=[2.]\n",
      "global_step=76921, episodic_return=[0.]\n",
      "global_step=77034, episodic_return=[0.]\n",
      "global_step=77147, episodic_return=[0.]\n",
      "global_step=77260, episodic_return=[0.]\n",
      "global_step=77467, episodic_return=[2.]\n",
      "global_step=77582, episodic_return=[0.]\n",
      "global_step=77695, episodic_return=[0.]\n",
      "global_step=77806, episodic_return=[0.]\n",
      "global_step=77962, episodic_return=[1.]\n",
      "global_step=78176, episodic_return=[3.]\n",
      "global_step=78364, episodic_return=[2.]\n",
      "global_step=78525, episodic_return=[1.]\n",
      "global_step=78638, episodic_return=[0.]\n",
      "global_step=78753, episodic_return=[0.]\n",
      "global_step=78940, episodic_return=[2.]\n",
      "global_step=79053, episodic_return=[0.]\n",
      "global_step=79311, episodic_return=[3.]\n",
      "global_step=79424, episodic_return=[0.]\n",
      "global_step=79583, episodic_return=[1.]\n",
      "global_step=79726, episodic_return=[1.]\n",
      "global_step=79990, episodic_return=[4.]\n",
      "SPS: 622\n",
      "global_step=80101, episodic_return=[0.]\n",
      "SPS: 619\n",
      "SPS: 616\n",
      "global_step=80342, episodic_return=[3.]\n",
      "SPS: 612\n",
      "SPS: 609\n",
      "global_step=80548, episodic_return=[2.]\n",
      "SPS: 606\n",
      "global_step=80663, episodic_return=[0.]\n",
      "SPS: 603\n",
      "SPS: 600\n",
      "global_step=80822, episodic_return=[1.]\n",
      "SPS: 597\n",
      "global_step=80983, episodic_return=[1.]\n",
      "SPS: 594\n",
      "global_step=81098, episodic_return=[0.]\n",
      "SPS: 591\n",
      "SPS: 588\n",
      "SPS: 585\n",
      "global_step=81332, episodic_return=[3.]\n",
      "SPS: 581\n",
      "SPS: 577\n",
      "global_step=81570, episodic_return=[3.]\n",
      "SPS: 574\n",
      "global_step=81683, episodic_return=[0.]\n",
      "SPS: 571\n",
      "SPS: 569\n",
      "SPS: 566\n",
      "global_step=81937, episodic_return=[3.]\n",
      "SPS: 564\n",
      "SPS: 561\n",
      "global_step=82110, episodic_return=[2.]\n",
      "SPS: 558\n",
      "global_step=82225, episodic_return=[0.]\n",
      "SPS: 556\n",
      "global_step=82340, episodic_return=[0.]\n",
      "SPS: 553\n",
      "global_step=82453, episodic_return=[0.]\n",
      "SPS: 546\n",
      "global_step=82568, episodic_return=[0.]\n",
      "SPS: 544\n",
      "SPS: 542\n",
      "global_step=82757, episodic_return=[2.]\n",
      "SPS: 539\n",
      "SPS: 537\n",
      "global_step=82993, episodic_return=[3.]\n",
      "SPS: 535\n",
      "SPS: 533\n",
      "global_step=83133, episodic_return=[1.]\n",
      "SPS: 531\n",
      "global_step=83294, episodic_return=[1.]\n",
      "SPS: 529\n",
      "SPS: 527\n",
      "SPS: 525\n",
      "global_step=83531, episodic_return=[3.]\n",
      "SPS: 523\n",
      "global_step=83693, episodic_return=[1.]\n",
      "SPS: 521\n",
      "SPS: 519\n",
      "SPS: 517\n",
      "global_step=83930, episodic_return=[3.]\n",
      "SPS: 515\n",
      "SPS: 513\n",
      "global_step=84136, episodic_return=[2.]\n",
      "SPS: 511\n",
      "global_step=84247, episodic_return=[0.]\n",
      "SPS: 509\n",
      "SPS: 507\n",
      "global_step=84484, episodic_return=[3.]\n",
      "SPS: 506\n",
      "SPS: 504\n",
      "global_step=84672, episodic_return=[2.]\n",
      "SPS: 502\n",
      "global_step=84783, episodic_return=[0.]\n",
      "SPS: 500\n",
      "global_step=84898, episodic_return=[0.]\n",
      "SPS: 498\n",
      "SPS: 496\n",
      "global_step=85011, episodic_return=[0.]\n",
      "SPS: 494\n",
      "SPS: 493\n",
      "global_step=85244, episodic_return=[3.]\n",
      "SPS: 491\n",
      "SPS: 489\n",
      "global_step=85454, episodic_return=[2.]\n",
      "SPS: 488\n",
      "SPS: 486\n",
      "global_step=85693, episodic_return=[3.]\n",
      "SPS: 484\n",
      "SPS: 483\n",
      "global_step=85804, episodic_return=[0.]\n",
      "SPS: 481\n",
      "global_step=85919, episodic_return=[0.]\n",
      "SPS: 480\n",
      "SPS: 478\n",
      "global_step=86109, episodic_return=[2.]\n",
      "SPS: 476\n",
      "SPS: 475\n",
      "global_step=86364, episodic_return=[4.]\n",
      "SPS: 473\n",
      "SPS: 471\n",
      "global_step=86598, episodic_return=[3.]\n",
      "SPS: 26\n",
      "SPS: 26\n",
      "global_step=86709, episodic_return=[0.]\n",
      "SPS: 26\n",
      "global_step=86822, episodic_return=[0.]\n",
      "SPS: 26\n",
      "global_step=86935, episodic_return=[0.]\n",
      "SPS: 26\n",
      "global_step=87094, episodic_return=[1.]\n",
      "SPS: 26\n",
      "SPS: 26\n",
      "global_step=87278, episodic_return=[2.]\n",
      "SPS: 26\n",
      "SPS: 26\n",
      "global_step=87437, episodic_return=[1.]\n",
      "SPS: 26\n",
      "global_step=87574, episodic_return=[1.]\n",
      "SPS: 13\n",
      "global_step=87689, episodic_return=[0.]\n",
      "SPS: 13\n",
      "SPS: 13\n",
      "global_step=87848, episodic_return=[1.]\n",
      "SPS: 13\n",
      "global_step=87989, episodic_return=[1.]\n",
      "SPS: 13\n",
      "SPS: 13\n",
      "global_step=88102, episodic_return=[0.]\n",
      "SPS: 13\n",
      "SPS: 13\n",
      "SPS: 13\n",
      "global_step=88407, episodic_return=[4.]\n",
      "SPS: 13\n",
      "global_step=88578, episodic_return=[2.]\n",
      "SPS: 9\n",
      "SPS: 9\n",
      "SPS: 9\n",
      "global_step=88816, episodic_return=[3.]\n",
      "SPS: 9\n",
      "global_step=88929, episodic_return=[0.]\n",
      "SPS: 9\n",
      "global_step=89040, episodic_return=[0.]\n",
      "SPS: 9\n",
      "SPS: 9\n",
      "global_step=89226, episodic_return=[2.]\n",
      "SPS: 9\n",
      "global_step=89339, episodic_return=[0.]\n",
      "SPS: 9\n",
      "SPS: 7\n",
      "global_step=89527, episodic_return=[2.]\n",
      "SPS: 7\n",
      "global_step=89642, episodic_return=[0.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=89994, episodic_return=[5.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=90109, episodic_return=[0.]\n",
      "SPS: 7\n",
      "global_step=90273, episodic_return=[1.]\n",
      "SPS: 7\n",
      "global_step=90388, episodic_return=[0.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=90501, episodic_return=[0.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=90769, episodic_return=[4.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=90910, episodic_return=[1.]\n",
      "SPS: 7\n",
      "global_step=91023, episodic_return=[0.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=91209, episodic_return=[2.]\n",
      "SPS: 7\n",
      "global_step=91350, episodic_return=[1.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=91562, episodic_return=[2.]\n",
      "SPS: 7\n",
      "global_step=91677, episodic_return=[0.]\n",
      "SPS: 7\n",
      "global_step=91790, episodic_return=[0.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=91995, episodic_return=[2.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=92181, episodic_return=[2.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=92417, episodic_return=[3.]\n",
      "SPS: 7\n",
      "global_step=92530, episodic_return=[0.]\n",
      "SPS: 7\n",
      "global_step=92691, episodic_return=[1.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=92899, episodic_return=[2.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=93014, episodic_return=[0.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=93202, episodic_return=[2.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=93437, episodic_return=[3.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=93696, episodic_return=[3.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=93837, episodic_return=[1.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=94149, episodic_return=[7.]\n",
      "SPS: 7\n",
      "global_step=94262, episodic_return=[0.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=94475, episodic_return=[2.]\n",
      "SPS: 7\n",
      "global_step=94590, episodic_return=[0.]\n",
      "SPS: 7\n",
      "SPS: 7\n",
      "global_step=94705, episodic_return=[0.]\n",
      "SPS: 8\n",
      "global_step=94816, episodic_return=[0.]\n",
      "SPS: 8\n",
      "global_step=94975, episodic_return=[1.]\n",
      "SPS: 8\n",
      "global_step=95090, episodic_return=[0.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=95252, episodic_return=[1.]\n",
      "SPS: 8\n",
      "global_step=95367, episodic_return=[0.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=95526, episodic_return=[1.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=95737, episodic_return=[2.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=96069, episodic_return=[5.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=96259, episodic_return=[2.]\n",
      "SPS: 8\n",
      "global_step=96372, episodic_return=[0.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=96611, episodic_return=[3.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=96817, episodic_return=[2.]\n",
      "SPS: 8\n",
      "global_step=96978, episodic_return=[1.]\n",
      "SPS: 8\n",
      "global_step=97091, episodic_return=[0.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=97279, episodic_return=[2.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=97516, episodic_return=[3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=97702, episodic_return=[2.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=98036, episodic_return=[5.]\n",
      "SPS: 8\n",
      "global_step=98197, episodic_return=[1.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=98453, episodic_return=[3.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=98612, episodic_return=[1.]\n",
      "SPS: 8\n",
      "global_step=98727, episodic_return=[0.]\n",
      "SPS: 8\n",
      "global_step=98842, episodic_return=[0.]\n",
      "SPS: 8\n",
      "global_step=98957, episodic_return=[0.]\n",
      "SPS: 8\n",
      "global_step=99068, episodic_return=[0.]\n",
      "SPS: 8\n",
      "global_step=99183, episodic_return=[0.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=99400, episodic_return=[3.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=99541, episodic_return=[1.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=99732, episodic_return=[2.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=99968, episodic_return=[3.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=100156, episodic_return=[2.]\n",
      "SPS: 8\n",
      "global_step=100269, episodic_return=[0.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=100426, episodic_return=[1.]\n",
      "SPS: 8\n",
      "global_step=100541, episodic_return=[0.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=100826, episodic_return=[4.]\n",
      "SPS: 8\n",
      "global_step=100941, episodic_return=[0.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=101181, episodic_return=[3.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=101563, episodic_return=[6.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=101722, episodic_return=[1.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=101911, episodic_return=[2.]\n",
      "SPS: 8\n",
      "global_step=102022, episodic_return=[0.]\n",
      "SPS: 8\n",
      "global_step=102163, episodic_return=[1.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=102321, episodic_return=[1.]\n",
      "SPS: 8\n",
      "SPS: 8\n",
      "global_step=102555, episodic_return=[3.]\n",
      "SPS: 8\n",
      "global_step=102698, episodic_return=[1.]\n",
      "SPS: 8\n"
     ]
    }
   ],
   "source": [
    "import stable_baselines3 as sb3\n",
    "\n",
    "if sb3.__version__ < \"2.0\":\n",
    "    raise ValueError(\n",
    "        \"\"\"Ongoing migration: run the following command to install the new dependencies:\n",
    "\n",
    "poetry run pip install \"stable_baselines3==2.0.0a1\" \"gymnasium[atari,accept-rom-license]==0.28.1\"  \"ale-py==0.8.1\" \n",
    "\"\"\"\n",
    "    )\n",
    "    \n",
    "args = parse_args()\n",
    "run_name = f\"{args.env_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
    "if args.track:\n",
    "    import wandb\n",
    "\n",
    "    wandb.init(\n",
    "        project=args.wandb_project_name,\n",
    "        entity=args.wandb_entity,\n",
    "        sync_tensorboard=True,\n",
    "        config=vars(args),\n",
    "        name=run_name,\n",
    "        monitor_gym=True,\n",
    "        save_code=True,\n",
    "    )\n",
    "writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "writer.add_text(\n",
    "    \"hyperparameters\",\n",
    "    \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(args).items()])),\n",
    ")\n",
    "\n",
    "# TRY NOT TO MODIFY: seeding\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.backends.cudnn.deterministic = args.torch_deterministic\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
    "\n",
    "# env setup\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [make_env(args.env_id, args.seed + i, i, args.capture_video, run_name) for i in range(args.num_envs)]\n",
    ")\n",
    "assert isinstance(envs.single_action_space, gym.spaces.Discrete), \"only discrete action space is supported\"\n",
    "\n",
    "q_network = QNetwork(envs).to(device)\n",
    "optimizer = optim.Adam(q_network.parameters(), lr=args.learning_rate)\n",
    "target_network = QNetwork(envs).to(device)\n",
    "target_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "rb = ReplayBuffer(\n",
    "    args.buffer_size,\n",
    "    envs.single_observation_space,\n",
    "    envs.single_action_space,\n",
    "    device,\n",
    "    optimize_memory_usage=True,\n",
    "    handle_timeout_termination=False,\n",
    ")\n",
    "start_time = time.time()\n",
    "\n",
    "# TRY NOT TO MODIFY: start the game\n",
    "obs, _ = envs.reset(seed=args.seed)\n",
    "for global_step in range(args.total_timesteps):\n",
    "    # ALGO LOGIC: put action logic here\n",
    "    epsilon = linear_schedule(args.start_e, args.end_e, args.exploration_fraction * args.total_timesteps, global_step)\n",
    "    if random.random() < epsilon:\n",
    "        actions = np.array([envs.single_action_space.sample() for _ in range(envs.num_envs)])\n",
    "    else:\n",
    "        q_values = q_network(torch.Tensor(obs).to(device))\n",
    "        actions = torch.argmax(q_values, dim=1).cpu().numpy()\n",
    "\n",
    "    # TRY NOT TO MODIFY: execute the game and log data.\n",
    "    next_obs, rewards, terminated, truncated, infos = envs.step(actions)\n",
    "\n",
    "    # TRY NOT TO MODIFY: record rewards for plotting purposes\n",
    "    if \"final_info\" in infos:\n",
    "        for info in infos[\"final_info\"]:\n",
    "            # Skip the envs that are not done\n",
    "            if \"episode\" not in info:\n",
    "                continue\n",
    "            print(f\"global_step={global_step}, episodic_return={info['episode']['r']}\")\n",
    "            writer.add_scalar(\"charts/episodic_return\", info[\"episode\"][\"r\"], global_step)\n",
    "            writer.add_scalar(\"charts/episodic_length\", info[\"episode\"][\"l\"], global_step)\n",
    "            writer.add_scalar(\"charts/epsilon\", epsilon, global_step)\n",
    "\n",
    "    # TRY NOT TO MODIFY: save data to reply buffer; handle `final_observation`\n",
    "    real_next_obs = next_obs.copy()\n",
    "    for idx, d in enumerate(truncated):\n",
    "        if d:\n",
    "            real_next_obs[idx] = infos[\"final_observation\"][idx]\n",
    "    rb.add(obs, real_next_obs, actions, rewards, terminated, infos)\n",
    "\n",
    "    # TRY NOT TO MODIFY: CRUCIAL step easy to overlook\n",
    "    obs = next_obs\n",
    "\n",
    "    # ALGO LOGIC: training.\n",
    "    if global_step > args.learning_starts:\n",
    "        if global_step % args.train_frequency == 0:\n",
    "            data = rb.sample(args.batch_size)\n",
    "            with torch.no_grad():\n",
    "                target_max, _ = target_network(data.next_observations).max(dim=1)\n",
    "                td_target = data.rewards.flatten() + args.gamma * target_max * (1 - data.dones.flatten())\n",
    "            old_val = q_network(data.observations).gather(1, data.actions).squeeze()\n",
    "            loss = F.mse_loss(td_target, old_val)\n",
    "\n",
    "            if global_step % 100 == 0:\n",
    "                writer.add_scalar(\"losses/td_loss\", loss, global_step)\n",
    "                writer.add_scalar(\"losses/q_values\", old_val.mean().item(), global_step)\n",
    "                print(\"SPS:\", int(global_step / (time.time() - start_time)))\n",
    "                writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
    "\n",
    "            # optimize the model\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # update target network\n",
    "        if global_step % args.target_network_frequency == 0:\n",
    "            for target_network_param, q_network_param in zip(target_network.parameters(), q_network.parameters()):\n",
    "                target_network_param.data.copy_(\n",
    "                    args.tau * q_network_param.data + (1.0 - args.tau) * target_network_param.data\n",
    "                )\n",
    "\n",
    "if args.save_model:\n",
    "    model_path = f\"runs/{run_name}/{args.exp_name}.cleanrl_model\"\n",
    "    torch.save(q_network.state_dict(), model_path)\n",
    "    print(f\"model saved to {model_path}\")\n",
    "    from cleanrl_utils.evals.dqn_eval import evaluate\n",
    "\n",
    "    episodic_returns = evaluate(\n",
    "        model_path,\n",
    "        make_env,\n",
    "        args.env_id,\n",
    "        eval_episodes=10,\n",
    "        run_name=f\"{run_name}-eval\",\n",
    "        Model=QNetwork,\n",
    "        device=device,\n",
    "        epsilon=0.05,\n",
    "    )\n",
    "    for idx, episodic_return in enumerate(episodic_returns):\n",
    "        writer.add_scalar(\"eval/episodic_return\", episodic_return, idx)\n",
    "\n",
    "    if args.upload_model:\n",
    "        from cleanrl_utils.huggingface import push_to_hub\n",
    "\n",
    "        repo_name = f\"{args.env_id}-{args.exp_name}-seed{args.seed}\"\n",
    "        repo_id = f\"{args.hf_entity}/{repo_name}\" if args.hf_entity else repo_name\n",
    "        push_to_hub(args, episodic_returns, repo_id, \"DQN\", f\"runs/{run_name}\", f\"videos/{run_name}-eval\")\n",
    "\n",
    "envs.close()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d476f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc9bbac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
